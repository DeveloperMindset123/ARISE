# -*- coding: utf-8 -*-
"""Dall-E vs Stabillity-Ai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gb1f0znuNdyxfwCUxfZQnTG4dxt5ByYz
"""

# Run the following command in the terminal and save it to a requirements.txt file --> recommended that you use a virtual environment when installing dependancies and running python scripts
#pip install --upgrade transformers
#pip install torch
#pip install diffusers
#pip install openai
#pip install matplotlib pillow
#pip install accelerate

import torch
from transformers import (AutoTokenizer,
CLIPModel,
CLIPFeatureExtractor,
CLIPTextModel,
CLIPVisionModel,
AutoTokenizer,
AutoModelForSeq2SeqLM,
FlaxAutoModelForSeq2SeqLM)
from diffusers import DiffusionPipeline, EulerDiscreteScheduler, StableDiffusionPipeline
from PIL import Image
from typing import Callable, List
from openai import OpenAI
import matplotlib.pyplot as plt
import time
import requests
import numpy as np

from huggingface_hub import notebook_login

# you will need to login prior to using your own huggingface models
notebook_login()

# Use the Euler scheduler here instead to load stable diffusion model
model_id = "CompVis/stable-diffusion-v1-4"
scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder="scheduler")
stable_diffusion_pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)
stable_diffusion_pipe = stable_diffusion_pipe.to("cuda")

# test
prompt = "a dog"
image = stable_diffusion_pipe(prompt).images[0]
print(image)

def generate_with_dalle(prompt, num_images=1):
    client = OpenAI(api_key="replace with your own openAI api key")
    response = client.images.generate(
        model="dall-e-3",
        prompt=prompt,
        size="1024x1024",
        quality="standard",
        n=num_images
    )
    return response


# test
result=generate_with_dalle("A dog")

image_url=result.data[0].url
im = Image.open(requests.get(image_url, stream=True).raw)
print(im)

def benchmark_model_openai(generate_func: Callable, prompt: str, num_runs: int = 1) -> float:
    start_time = time.time()
    for _ in range(num_runs):
        generate_func(prompt)
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    print(f"Average inference time for '{prompt}': {avg_time:.2f} seconds")
    return avg_time

# Use the function to benchmark DALL-E
print("Benchmarking DALL-E...")
dalle_time = benchmark_model_openai(lambda p: generate_with_dalle(p, 1), "A digital artwork of a fantastical dragon in the sky", num_runs=3)

def benchmark_model_diffusers(model: DiffusionPipeline, prompt: str, num_runs: int = 1) -> float:
    start_time = time.time()
    for _ in range(num_runs):
        model(prompt)
    end_time = time.time()
    avg_time = (end_time - start_time) / num_runs
    print(f"Average inference time for '{prompt}': {avg_time:.2f} seconds")
    return avg_time

# Benchmarking Stable Diffusion
print("Benchmarking Stable Diffusion...")
sd_time = benchmark_model_diffusers(stable_diffusion_pipe, "A digital artwork of a fantastical dragon in the sky", num_runs=3)

print(f"\nPerformance Summary:")
print(f"Stable Diffusion Avg Time: {sd_time:.2f} seconds")
print(f"DALL-E Avg Time: {dalle_time:.2f} seconds")

if sd_time < dalle_time:
    print("Stable Diffusion is faster.")
else:
    print("DALL-E is faster.")

# graph the results
import matplotlib.pyplot as plt

def plot_benchmark_results(sd_time: float, dalle_time: float):
    labels = ['Stable Diffusion', 'DALL-E']
    times = [sd_time, dalle_time]

    plt.figure(figsize=(10, 5))
    plt.bar(labels, times, color=['blue', 'green'])
    plt.xlabel('Model')
    plt.ylabel('Average Inference Time (seconds)')
    plt.title('Benchmarking Model Performance')
    plt.show()

# Perform benchmarking
print("Benchmarking Stable Diffusion...")
sd_time = benchmark_model_diffusers(stable_diffusion_pipe, "A surreal painting of a futuristic city", num_runs=3)

print("Benchmarking DALL-E...")
dalle_time = benchmark_model_openai(lambda p: generate_with_dalle(p, 1), "A surreal painting of a futuristic city", num_runs=3)

# Generate and display images
sd_images = stable_diffusion_pipe("A surreal painting of a futuristic city")
dalle_images = generate_with_dalle("A surreal painting of a futuristic city")
# alternate prompt for testing : A digital artwork of a fantastical dragon in the sky
# Plot benchmark results
plot_benchmark_results(sd_time, dalle_time)

# Performance summary
print(f"\nPerformance Summary:")
print(f"Stable Diffusion Avg Time: {sd_time:.2f} seconds")
print(f"DALL-E Avg Time: {dalle_time:.2f} seconds")

if sd_time < dalle_time:
    print("Stable Diffusion is faster.")
else:
    print("DALL-E is faster.")

# Lastly, check the images to see what they look like
print("Resulting Stable Diffusion Model Image:\n")
sd_images.images[0]

print("Resulting Dall-E Generated Image: \n")
dalle_images_raw = Image.open(requests.get(dalle_images.data[0].url, stream=True).raw)

print(dalle_images_raw)

